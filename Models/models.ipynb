{"cells":[{"cell_type":"code","execution_count":null,"id":"2cf0af11","metadata":{"id":"2cf0af11","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1756055720862,"user_tz":-330,"elapsed":358026,"user":{"displayName":"Pranav Bhat","userId":"05304972169025204322"}},"outputId":"4cde05dc-7190-444e-c308-32beb00f1d62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data loaded and merged successfully.\n","DataFrame shape: (3842, 144)\n","\n","--- Class Distribution Analysis ---\n","Number of unique crisis levels (classes): 4\n","Unique target values: [0 1 2 3]\n","\n","Overall class distribution in the entire dataset:\n","Crisis_Target_V2\n","0    1295\n","1    1673\n","2     747\n","3     127\n","Name: count, dtype: int64\n","\n","--- Starting 5-Fold Time-Series Cross-Validation ---\n","\n","===== FOLD 1/5 =====\n","Class Weights for this fold: {0: np.float64(1.2901234567901234), 1: np.float64(0.5147783251231527), 2: np.float64(3.542372881355932)}\n","Epoch 1/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step - accuracy: 0.3808 - loss: 1.0647 - val_accuracy: 0.5104 - val_loss: 1.3671\n","Epoch 2/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.7820 - loss: 0.3299 - val_accuracy: 0.6288 - val_loss: 1.7804\n","Epoch 3/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9360 - loss: 0.1695 - val_accuracy: 0.6304 - val_loss: 1.5397\n","Epoch 4/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9477 - loss: 0.1101 - val_accuracy: 0.6640 - val_loss: 1.3374\n","Epoch 5/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9508 - loss: 0.1094 - val_accuracy: 0.6304 - val_loss: 1.4767\n","Epoch 6/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9608 - loss: 0.1055 - val_accuracy: 0.6288 - val_loss: 1.5434\n","Epoch 7/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9726 - loss: 0.0822 - val_accuracy: 0.5584 - val_loss: 1.6952\n","Epoch 8/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9542 - loss: 0.1039 - val_accuracy: 0.6080 - val_loss: 1.7129\n","Epoch 9/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9698 - loss: 0.0731 - val_accuracy: 0.6384 - val_loss: 1.4573\n","Epoch 10/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9561 - loss: 0.1132 - val_accuracy: 0.5472 - val_loss: 2.6515\n","Epoch 11/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9597 - loss: 0.0920 - val_accuracy: 0.6080 - val_loss: 2.6705\n","Epoch 12/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9767 - loss: 0.0723 - val_accuracy: 0.5712 - val_loss: 1.7311\n","Epoch 13/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9649 - loss: 0.0701 - val_accuracy: 0.6128 - val_loss: 1.8737\n","Epoch 14/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9810 - loss: 0.0496 - val_accuracy: 0.5776 - val_loss: 2.2257\n","Epoch 15/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9572 - loss: 0.0825 - val_accuracy: 0.5888 - val_loss: 1.8412\n","Epoch 16/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9825 - loss: 0.0526 - val_accuracy: 0.6512 - val_loss: 1.2292\n","Epoch 17/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9715 - loss: 0.0693 - val_accuracy: 0.6128 - val_loss: 1.9398\n","Epoch 18/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9751 - loss: 0.0701 - val_accuracy: 0.6160 - val_loss: 1.4238\n","Epoch 19/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9670 - loss: 0.0567 - val_accuracy: 0.6176 - val_loss: 1.5671\n","Epoch 20/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9682 - loss: 0.0380 - val_accuracy: 0.6048 - val_loss: 1.5387\n","Epoch 21/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9777 - loss: 0.0473 - val_accuracy: 0.5984 - val_loss: 1.7462\n","Epoch 22/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9849 - loss: 0.0445 - val_accuracy: 0.6144 - val_loss: 1.6332\n","Epoch 23/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9762 - loss: 0.0583 - val_accuracy: 0.6272 - val_loss: 1.4783\n","Epoch 24/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9772 - loss: 0.0400 - val_accuracy: 0.6240 - val_loss: 1.9061\n","Epoch 25/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9756 - loss: 0.0573 - val_accuracy: 0.5456 - val_loss: 2.2146\n","Epoch 26/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9723 - loss: 0.0564 - val_accuracy: 0.6784 - val_loss: 1.3860\n","Epoch 27/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9744 - loss: 0.0513 - val_accuracy: 0.7120 - val_loss: 1.3615\n","Epoch 28/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9693 - loss: 0.0751 - val_accuracy: 0.6304 - val_loss: 1.4518\n","Epoch 29/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9670 - loss: 0.0594 - val_accuracy: 0.6224 - val_loss: 1.3876\n","Epoch 30/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9680 - loss: 0.0507 - val_accuracy: 0.6016 - val_loss: 1.4657\n","Epoch 31/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9757 - loss: 0.0411 - val_accuracy: 0.5984 - val_loss: 1.5387\n","Epoch 32/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9780 - loss: 0.0434 - val_accuracy: 0.5520 - val_loss: 1.4618\n","Epoch 33/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9731 - loss: 0.0600 - val_accuracy: 0.5968 - val_loss: 1.5630\n","Epoch 34/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9826 - loss: 0.0393 - val_accuracy: 0.5728 - val_loss: 1.6948\n","Epoch 35/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9687 - loss: 0.0645 - val_accuracy: 0.6016 - val_loss: 1.4916\n","Epoch 36/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9848 - loss: 0.0434 - val_accuracy: 0.7216 - val_loss: 1.3079\n","Epoch 36: early stopping\n","Restoring model weights from the end of the best epoch: 16.\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n","Accuracy for Fold 1: 0.6512\n","\n","===== FOLD 2/5 =====\n","Class Weights for this fold: {0: np.float64(1.2620967741935485), 1: np.float64(0.45894428152492667), 2: np.float64(1.1258992805755397), 3: np.float64(7.113636363636363)}\n","Epoch 1/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.4207 - loss: 1.1125 - val_accuracy: 0.8240 - val_loss: 0.5965\n","Epoch 2/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8529 - loss: 0.3711 - val_accuracy: 0.8096 - val_loss: 0.5147\n","Epoch 3/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9109 - loss: 0.2132 - val_accuracy: 0.7280 - val_loss: 0.5687\n","Epoch 4/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9291 - loss: 0.1620 - val_accuracy: 0.8528 - val_loss: 0.2835\n","Epoch 5/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9524 - loss: 0.1138 - val_accuracy: 0.8688 - val_loss: 0.3941\n","Epoch 6/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9383 - loss: 0.1474 - val_accuracy: 0.6976 - val_loss: 1.1407\n","Epoch 7/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9230 - loss: 0.1397 - val_accuracy: 0.8448 - val_loss: 0.5263\n","Epoch 8/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9533 - loss: 0.1028 - val_accuracy: 0.8912 - val_loss: 0.3400\n","Epoch 9/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9622 - loss: 0.0735 - val_accuracy: 0.8960 - val_loss: 0.3084\n","Epoch 10/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9708 - loss: 0.0937 - val_accuracy: 0.8864 - val_loss: 0.4304\n","Epoch 11/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9618 - loss: 0.0971 - val_accuracy: 0.8192 - val_loss: 0.4713\n","Epoch 12/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9752 - loss: 0.0666 - val_accuracy: 0.8528 - val_loss: 0.3762\n","Epoch 13/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9624 - loss: 0.0887 - val_accuracy: 0.9168 - val_loss: 0.2342\n","Epoch 14/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9717 - loss: 0.0623 - val_accuracy: 0.8912 - val_loss: 0.2967\n","Epoch 15/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9686 - loss: 0.0740 - val_accuracy: 0.9360 - val_loss: 0.1938\n","Epoch 16/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9823 - loss: 0.0481 - val_accuracy: 0.9568 - val_loss: 0.1443\n","Epoch 17/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9712 - loss: 0.0759 - val_accuracy: 0.9312 - val_loss: 0.2359\n","Epoch 18/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9774 - loss: 0.0618 - val_accuracy: 0.8608 - val_loss: 0.3129\n","Epoch 19/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9698 - loss: 0.0710 - val_accuracy: 0.9520 - val_loss: 0.1902\n","Epoch 20/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9662 - loss: 0.0634 - val_accuracy: 0.9216 - val_loss: 0.2662\n","Epoch 21/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9781 - loss: 0.0732 - val_accuracy: 0.9296 - val_loss: 0.2373\n","Epoch 22/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9790 - loss: 0.0466 - val_accuracy: 0.9520 - val_loss: 0.1502\n","Epoch 23/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9758 - loss: 0.0550 - val_accuracy: 0.9248 - val_loss: 0.2391\n","Epoch 24/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9711 - loss: 0.0618 - val_accuracy: 0.9136 - val_loss: 0.2684\n","Epoch 25/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9732 - loss: 0.0862 - val_accuracy: 0.8192 - val_loss: 0.3303\n","Epoch 26/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9682 - loss: 0.0780 - val_accuracy: 0.9344 - val_loss: 0.1984\n","Epoch 27/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9782 - loss: 0.0570 - val_accuracy: 0.9008 - val_loss: 0.2710\n","Epoch 28/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9753 - loss: 0.0552 - val_accuracy: 0.8768 - val_loss: 0.3801\n","Epoch 29/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9697 - loss: 0.1019 - val_accuracy: 0.9248 - val_loss: 0.2244\n","Epoch 30/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9859 - loss: 0.0410 - val_accuracy: 0.9520 - val_loss: 0.1850\n","Epoch 31/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9800 - loss: 0.0461 - val_accuracy: 0.9600 - val_loss: 0.1812\n","Epoch 32/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9809 - loss: 0.0483 - val_accuracy: 0.9648 - val_loss: 0.1546\n","Epoch 33/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9821 - loss: 0.0454 - val_accuracy: 0.8992 - val_loss: 0.3705\n","Epoch 34/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9803 - loss: 0.0362 - val_accuracy: 0.9408 - val_loss: 0.1914\n","Epoch 35/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9816 - loss: 0.0326 - val_accuracy: 0.9056 - val_loss: 0.3164\n","Epoch 36/100\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9784 - loss: 0.0437 - val_accuracy: 0.8784 - val_loss: 0.5320\n","Epoch 36: early stopping\n","Restoring model weights from the end of the best epoch: 16.\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n","Accuracy for Fold 2: 0.9568\n","\n","===== FOLD 3/5 =====\n","Class Weights for this fold: {0: np.float64(1.2751358695652173), 1: np.float64(0.49239244491080797), 2: np.float64(1.093822843822844), 3: np.float64(3.6948818897637796)}\n","Epoch 1/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.5915 - loss: 0.8331 - val_accuracy: 0.5504 - val_loss: 1.2651\n","Epoch 2/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8882 - loss: 0.2833 - val_accuracy: 0.5696 - val_loss: 0.9591\n","Epoch 3/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9196 - loss: 0.1879 - val_accuracy: 0.5904 - val_loss: 1.3789\n","Epoch 4/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9470 - loss: 0.1294 - val_accuracy: 0.3712 - val_loss: 1.9264\n","Epoch 5/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9668 - loss: 0.0837 - val_accuracy: 0.2880 - val_loss: 2.2303\n","Epoch 6/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9605 - loss: 0.0856 - val_accuracy: 0.2448 - val_loss: 1.9885\n","Epoch 7/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9749 - loss: 0.0718 - val_accuracy: 0.5408 - val_loss: 1.8913\n","Epoch 8/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9698 - loss: 0.0595 - val_accuracy: 0.5104 - val_loss: 2.1082\n","Epoch 9/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9631 - loss: 0.0904 - val_accuracy: 0.4688 - val_loss: 2.0787\n","Epoch 10/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9686 - loss: 0.0713 - val_accuracy: 0.4368 - val_loss: 2.0990\n","Epoch 11/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9712 - loss: 0.0673 - val_accuracy: 0.5280 - val_loss: 2.0091\n","Epoch 12/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9646 - loss: 0.0878 - val_accuracy: 0.3008 - val_loss: 2.5394\n","Epoch 13/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9618 - loss: 0.0850 - val_accuracy: 0.4640 - val_loss: 2.0834\n","Epoch 14/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9729 - loss: 0.0540 - val_accuracy: 0.3376 - val_loss: 2.5587\n","Epoch 15/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9730 - loss: 0.0811 - val_accuracy: 0.5664 - val_loss: 2.2650\n","Epoch 16/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9770 - loss: 0.0521 - val_accuracy: 0.4736 - val_loss: 2.3187\n","Epoch 17/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9833 - loss: 0.0521 - val_accuracy: 0.3504 - val_loss: 3.0462\n","Epoch 18/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9673 - loss: 0.0648 - val_accuracy: 0.5904 - val_loss: 1.5973\n","Epoch 19/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9797 - loss: 0.0515 - val_accuracy: 0.5600 - val_loss: 1.9658\n","Epoch 20/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9765 - loss: 0.0560 - val_accuracy: 0.4752 - val_loss: 1.8383\n","Epoch 21/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9845 - loss: 0.0306 - val_accuracy: 0.4592 - val_loss: 2.4541\n","Epoch 22/100\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9814 - loss: 0.0432 - val_accuracy: 0.4064 - val_loss: 2.4184\n","Epoch 22: early stopping\n","Restoring model weights from the end of the best epoch: 2.\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n","Accuracy for Fold 3: 0.5696\n","\n","===== FOLD 4/5 =====\n","Class Weights for this fold: {0: np.float64(0.8663434903047091), 1: np.float64(0.5434404865334492), 2: np.float64(1.24601593625498), 3: np.float64(4.925196850393701)}\n","Epoch 1/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.5478 - loss: 0.8729 - val_accuracy: 0.5424 - val_loss: 1.5981\n","Epoch 2/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9175 - loss: 0.2004 - val_accuracy: 0.6544 - val_loss: 0.7749\n","Epoch 3/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9302 - loss: 0.1765 - val_accuracy: 0.6080 - val_loss: 1.1645\n","Epoch 4/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9190 - loss: 0.1640 - val_accuracy: 0.6048 - val_loss: 1.1318\n","Epoch 5/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9650 - loss: 0.0887 - val_accuracy: 0.5776 - val_loss: 1.6904\n","Epoch 6/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9548 - loss: 0.1313 - val_accuracy: 0.6912 - val_loss: 0.8975\n","Epoch 7/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9661 - loss: 0.0880 - val_accuracy: 0.5456 - val_loss: 2.4563\n","Epoch 8/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8929 - loss: 0.1985 - val_accuracy: 0.7248 - val_loss: 0.7298\n","Epoch 9/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9745 - loss: 0.0660 - val_accuracy: 0.6832 - val_loss: 0.9260\n","Epoch 10/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9707 - loss: 0.0746 - val_accuracy: 0.6640 - val_loss: 1.0966\n","Epoch 11/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9659 - loss: 0.1027 - val_accuracy: 0.6912 - val_loss: 0.9364\n","Epoch 12/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9640 - loss: 0.0942 - val_accuracy: 0.7392 - val_loss: 0.7101\n","Epoch 13/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9678 - loss: 0.0892 - val_accuracy: 0.7056 - val_loss: 0.7325\n","Epoch 14/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9751 - loss: 0.0693 - val_accuracy: 0.7520 - val_loss: 0.8280\n","Epoch 15/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9756 - loss: 0.0595 - val_accuracy: 0.6656 - val_loss: 1.0393\n","Epoch 16/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9737 - loss: 0.0818 - val_accuracy: 0.7360 - val_loss: 0.6827\n","Epoch 17/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9797 - loss: 0.0672 - val_accuracy: 0.7600 - val_loss: 0.6319\n","Epoch 18/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9788 - loss: 0.0556 - val_accuracy: 0.7488 - val_loss: 0.6799\n","Epoch 19/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9836 - loss: 0.0487 - val_accuracy: 0.7536 - val_loss: 0.7592\n","Epoch 20/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9735 - loss: 0.0602 - val_accuracy: 0.7296 - val_loss: 0.7415\n","Epoch 21/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9754 - loss: 0.0602 - val_accuracy: 0.7456 - val_loss: 0.6240\n","Epoch 22/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9845 - loss: 0.0430 - val_accuracy: 0.7120 - val_loss: 1.0235\n","Epoch 23/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9719 - loss: 0.0784 - val_accuracy: 0.7072 - val_loss: 0.7467\n","Epoch 24/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9276 - loss: 0.1246 - val_accuracy: 0.7328 - val_loss: 0.9330\n","Epoch 25/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9540 - loss: 0.1176 - val_accuracy: 0.7264 - val_loss: 0.8873\n","Epoch 26/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9836 - loss: 0.0448 - val_accuracy: 0.7584 - val_loss: 0.8120\n","Epoch 27/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9822 - loss: 0.0411 - val_accuracy: 0.7376 - val_loss: 0.7608\n","Epoch 28/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9795 - loss: 0.0525 - val_accuracy: 0.7456 - val_loss: 0.9558\n","Epoch 29/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9831 - loss: 0.0475 - val_accuracy: 0.7376 - val_loss: 0.7794\n","Epoch 30/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9428 - loss: 0.1164 - val_accuracy: 0.7520 - val_loss: 0.9007\n","Epoch 31/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9823 - loss: 0.0541 - val_accuracy: 0.7504 - val_loss: 0.8347\n","Epoch 32/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9837 - loss: 0.0386 - val_accuracy: 0.6912 - val_loss: 1.2796\n","Epoch 33/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9813 - loss: 0.0476 - val_accuracy: 0.7360 - val_loss: 1.1071\n","Epoch 34/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9831 - loss: 0.0396 - val_accuracy: 0.7520 - val_loss: 0.8923\n","Epoch 35/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9865 - loss: 0.0352 - val_accuracy: 0.7472 - val_loss: 0.8796\n","Epoch 36/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9706 - loss: 0.0637 - val_accuracy: 0.7152 - val_loss: 1.0693\n","Epoch 37/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9791 - loss: 0.0503 - val_accuracy: 0.7664 - val_loss: 0.7137\n","Epoch 38/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9877 - loss: 0.0334 - val_accuracy: 0.7776 - val_loss: 0.7042\n","Epoch 39/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9816 - loss: 0.0412 - val_accuracy: 0.7488 - val_loss: 0.7805\n","Epoch 40/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9876 - loss: 0.0335 - val_accuracy: 0.7456 - val_loss: 0.8939\n","Epoch 41/100\n","\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9866 - loss: 0.0335 - val_accuracy: 0.7568 - val_loss: 0.6845\n","Epoch 41: early stopping\n","Restoring model weights from the end of the best epoch: 21.\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n","Accuracy for Fold 4: 0.7456\n","\n","===== FOLD 5/5 =====\n","Class Weights for this fold: {0: np.float64(0.7438154138915318), 1: np.float64(0.5560099573257468), 2: np.float64(1.4396869244935544), 3: np.float64(6.155511811023622)}\n","Epoch 1/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.6055 - loss: 0.8369 - val_accuracy: 0.7408 - val_loss: 0.5200\n","Epoch 2/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9019 - loss: 0.2324 - val_accuracy: 0.6688 - val_loss: 0.7049\n","Epoch 3/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8956 - loss: 0.1998 - val_accuracy: 0.7040 - val_loss: 0.8308\n","Epoch 4/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9308 - loss: 0.1507 - val_accuracy: 0.8256 - val_loss: 0.3976\n","Epoch 5/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9252 - loss: 0.1774 - val_accuracy: 0.6912 - val_loss: 0.5975\n","Epoch 6/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9277 - loss: 0.1480 - val_accuracy: 0.7568 - val_loss: 0.4733\n","Epoch 7/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9441 - loss: 0.1143 - val_accuracy: 0.8720 - val_loss: 0.2786\n","Epoch 8/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9392 - loss: 0.1125 - val_accuracy: 0.8688 - val_loss: 0.3089\n","Epoch 9/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9520 - loss: 0.1138 - val_accuracy: 0.8704 - val_loss: 0.2991\n","Epoch 10/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9421 - loss: 0.1025 - val_accuracy: 0.8480 - val_loss: 0.3877\n","Epoch 11/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9449 - loss: 0.1033 - val_accuracy: 0.8528 - val_loss: 0.3522\n","Epoch 12/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9452 - loss: 0.1149 - val_accuracy: 0.8112 - val_loss: 0.4679\n","Epoch 13/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9449 - loss: 0.1052 - val_accuracy: 0.8288 - val_loss: 0.4416\n","Epoch 14/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9541 - loss: 0.0889 - val_accuracy: 0.8736 - val_loss: 0.3306\n","Epoch 15/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9506 - loss: 0.0992 - val_accuracy: 0.9008 - val_loss: 0.2342\n","Epoch 16/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9558 - loss: 0.0863 - val_accuracy: 0.8784 - val_loss: 0.2826\n","Epoch 17/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9609 - loss: 0.1033 - val_accuracy: 0.8416 - val_loss: 0.4082\n","Epoch 18/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9521 - loss: 0.0904 - val_accuracy: 0.8480 - val_loss: 0.3389\n","Epoch 19/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9541 - loss: 0.0910 - val_accuracy: 0.8544 - val_loss: 0.3508\n","Epoch 20/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9564 - loss: 0.1002 - val_accuracy: 0.8880 - val_loss: 0.2597\n","Epoch 21/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9561 - loss: 0.0923 - val_accuracy: 0.8128 - val_loss: 0.3561\n","Epoch 22/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9453 - loss: 0.0986 - val_accuracy: 0.7824 - val_loss: 0.5504\n","Epoch 23/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9622 - loss: 0.0859 - val_accuracy: 0.8512 - val_loss: 0.3191\n","Epoch 24/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9720 - loss: 0.0670 - val_accuracy: 0.8768 - val_loss: 0.3079\n","Epoch 25/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9592 - loss: 0.0828 - val_accuracy: 0.8576 - val_loss: 0.3169\n","Epoch 26/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9603 - loss: 0.0781 - val_accuracy: 0.8656 - val_loss: 0.3061\n","Epoch 27/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9597 - loss: 0.0852 - val_accuracy: 0.8848 - val_loss: 0.2521\n","Epoch 28/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9639 - loss: 0.0811 - val_accuracy: 0.8912 - val_loss: 0.2688\n","Epoch 29/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9560 - loss: 0.0894 - val_accuracy: 0.8336 - val_loss: 0.3529\n","Epoch 30/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9545 - loss: 0.0881 - val_accuracy: 0.8400 - val_loss: 0.4198\n","Epoch 31/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9596 - loss: 0.1101 - val_accuracy: 0.8384 - val_loss: 0.3759\n","Epoch 32/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9592 - loss: 0.0879 - val_accuracy: 0.9216 - val_loss: 0.2397\n","Epoch 33/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9616 - loss: 0.0927 - val_accuracy: 0.8832 - val_loss: 0.2735\n","Epoch 34/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9639 - loss: 0.0789 - val_accuracy: 0.8496 - val_loss: 0.3517\n","Epoch 35/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9602 - loss: 0.0796 - val_accuracy: 0.8848 - val_loss: 0.2647\n","Epoch 35: early stopping\n","Restoring model weights from the end of the best epoch: 15.\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n","Accuracy for Fold 5: 0.9008\n","\n","\n","--- Overall Model Performance (Across All Folds) ---\n","Average Cross-Validation Accuracy: 0.7648 (+/- 0.1461)\n","\n","Overall Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.87      0.83      1133\n","           1       0.72      0.74      0.73      1226\n","           2       0.76      0.65      0.70       639\n","           3       1.00      0.57      0.73       127\n","\n","    accuracy                           0.76      3125\n","   macro avg       0.82      0.71      0.75      3125\n","weighted avg       0.77      0.76      0.76      3125\n","\n","\n","--- Plotting Overall Confusion Matrix ---\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x800 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Confusion Matrix plot displayed.\n","\n","\n","--- Training Final Model on All Data for Prediction ---\n","Final Class Weights: {0: np.float64(0.7243243243243244), 1: np.float64(0.5747549019607843), 2: np.float64(1.343839541547278), 3: np.float64(7.3858267716535435)}\n","Epoch 1/30\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.5931 - loss: 0.8071\n","Epoch 2/30\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8832 - loss: 0.2578\n","Epoch 3/30\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9097 - loss: 0.1985\n","Epoch 4/30\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9253 - loss: 0.1499\n","Epoch 5/30\n","\u001b[1m 1/59\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9062 - loss: 0.2466"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2052882368.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;31m# --- Train the final model on the entire dataset ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m final_model.fit(\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mX_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0my_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import TimeSeriesSplit\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Bidirectional\n","from tensorflow.keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# --- 1. Load and Prepare Data ---\n","np.random.seed(42)\n","random.seed(42)\n","tf.random.set_seed(42)\n","try:\n","    # Load the features and target datasets\n","    features_df = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/E:/projects/water_crises_management/chennaiWaterCrisis/Datasets/chennai_features_for_lstm.csv')\n","    target_df = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/E:/projects/water_crises_management/chennaiWaterCrisis/Datasets/chennai_target_for_lstm.csv')\n","\n","    # Convert 'Date' column to datetime objects\n","    features_df['Date'] = pd.to_datetime(features_df['Date'])\n","    target_df['Date'] = pd.to_datetime(target_df['Date'])\n","\n","    # Merge the two dataframes on the 'Date' column\n","    df = pd.merge(features_df, target_df, on='Date')\n","\n","    # Set 'Date' as the index\n","    df.set_index('Date', inplace=True)\n","\n","    print(\"Data loaded and merged successfully.\")\n","    print(\"DataFrame shape:\", df.shape)\n","\n","except FileNotFoundError as e:\n","    print(f\"Error: {e}. Please make sure 'chennai_features_for_lstm.csv' and 'chennai_target_for_lstm.csv' are in the same directory as the script.\")\n","    exit()\n","\n","\n","# --- 2. Preprocess the Data ---\n","\n","# Separate features (X) and target (y)\n","X_df = df.drop('Crisis_Target_V2', axis=1)\n","y_df = df['Crisis_Target_V2']\n","\n","# --- Diagnostic: Check Class Distribution ---\n","print(\"\\n--- Class Distribution Analysis ---\")\n","num_classes = len(y_df.unique())\n","print(f\"Number of unique crisis levels (classes): {num_classes}\")\n","print(f\"Unique target values: {np.sort(y_df.unique())}\")\n","print(\"\\nOverall class distribution in the entire dataset:\")\n","print(y_df.value_counts().sort_index())\n","\n","# Validate that labels are in the correct range [0, num_classes-1]\n","if y_df.min() < 0:\n","    print(f\"Error: Negative label found ({y_df.min()}). Labels must be non-negative.\")\n","    exit()\n","\n","\n","# Scale the features to be between 0 and 1.\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","X_scaled = scaler.fit_transform(X_df)\n","\n","# --- 3. Create Time-Series Sequences ---\n","def create_dataset(X, y, time_step=1):\n","    dataX, dataY = [], []\n","    for i in range(len(X) - time_step):\n","        a = X[i:(i + time_step), :]\n","        dataX.append(a)\n","        dataY.append(y[i + time_step])\n","    return np.array(dataX), np.array(dataY)\n","\n","# **TUNED HYPERPARAMETER**: Changed time_step to 90\n","time_step = 90\n","X_seq, y_seq = create_dataset(X_scaled, y_df.values, time_step)\n","\n","\n","# --- 4. Build and Train the Model with Cross-Validation ---\n","\n","# Use TimeSeriesSplit for robust cross-validation on time-series data.\n","n_splits = 5\n","tscv = TimeSeriesSplit(n_splits=n_splits)\n","\n","# Store scores and histories from each fold\n","fold_accuracies = []\n","all_y_test = []\n","all_y_pred = []\n","\n","print(f\"\\n--- Starting {n_splits}-Fold Time-Series Cross-Validation ---\")\n","\n","for fold, (train_index, test_index) in enumerate(tscv.split(X_seq)):\n","    print(f\"\\n===== FOLD {fold + 1}/{n_splits} =====\")\n","    X_train, X_test = X_seq[train_index], X_seq[test_index]\n","    y_train, y_test = y_seq[train_index], y_seq[test_index]\n","\n","    # --- Handle Class Imbalance with Class Weights ---\n","    class_weights = compute_class_weight(\n","        class_weight='balanced',\n","        classes=np.unique(y_train),\n","        y=y_train\n","    )\n","    class_weights_dict = dict(enumerate(class_weights))\n","    print(\"Class Weights for this fold:\", class_weights_dict)\n","\n","    # --- Build the Bidirectional LSTM Model ---\n","    # This architecture can capture patterns from both past-to-future and future-to-past.\n","    model = Sequential([\n","        Input(shape=(time_step, X_train.shape[2])),\n","        Bidirectional(LSTM(150, return_sequences=True)), # Using Bidirectional wrapper\n","        Dropout(0.2),\n","        Bidirectional(LSTM(150, return_sequences=True)), # Using Bidirectional wrapper\n","        Dropout(0.2),\n","        Bidirectional(LSTM(64)), # Using Bidirectional wrapper\n","        Dropout(0.2),\n","        Dense(64, activation='relu'),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    # --- Use Early Stopping to Prevent Overfitting ---\n","    early_stopping = EarlyStopping(\n","        monitor='val_loss',\n","        patience=20,\n","        verbose=1,\n","        restore_best_weights=True\n","    )\n","\n","    # --- Train the Model ---\n","    history = model.fit(\n","        X_train,\n","        y_train,\n","        validation_data=(X_test, y_test),\n","        epochs=100,\n","        batch_size=64,\n","        class_weight=class_weights_dict,\n","        callbacks=[early_stopping],\n","        verbose=1\n","    )\n","\n","    # --- Evaluate on the test fold ---\n","    y_pred_probs = model.predict(X_test)\n","    y_pred = np.argmax(y_pred_probs, axis=1)\n","\n","    fold_accuracy = accuracy_score(y_test, y_pred)\n","    fold_accuracies.append(fold_accuracy)\n","    print(f\"Accuracy for Fold {fold + 1}: {fold_accuracy:.4f}\")\n","\n","    # Store results for final evaluation\n","    all_y_test.extend(y_test)\n","    all_y_pred.extend(y_pred)\n","\n","\n","# --- 5. Final Model Evaluation ---\n","print(\"\\n\\n--- Overall Model Performance (Across All Folds) ---\")\n","print(f\"Average Cross-Validation Accuracy: {np.mean(fold_accuracies):.4f} (+/- {np.std(fold_accuracies):.4f})\")\n","\n","# --- Overall Classification Report ---\n","print(\"\\nOverall Classification Report:\")\n","report = classification_report(all_y_test, all_y_pred, labels=np.sort(y_df.unique()), zero_division=0)\n","print(report)\n","\n","# --- Overall Confusion Matrix ---\n","print(\"\\n--- Plotting Overall Confusion Matrix ---\")\n","cm = confusion_matrix(all_y_test, all_y_pred, labels=np.sort(y_df.unique()))\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=np.sort(y_df.unique()),\n","            yticklabels=np.sort(y_df.unique()))\n","plt.title('Overall Confusion Matrix (All Folds)', fontsize=16, fontweight='bold')\n","plt.ylabel('Actual Label', fontsize=12)\n","plt.xlabel('Predicted Label', fontsize=12)\n","plt.show()\n","print(\"Confusion Matrix plot displayed.\")\n","\n","\n","# --- 6. Train Final Model and Make Prediction for Tomorrow ---\n","\n","print(\"\\n\\n--- Training Final Model on All Data for Prediction ---\")\n","\n","# --- Handle Class Imbalance for the full dataset ---\n","final_class_weights = compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(y_seq),\n","    y=y_seq\n",")\n","final_class_weights_dict = dict(enumerate(final_class_weights))\n","print(\"Final Class Weights:\", final_class_weights_dict)\n","\n","# --- Build the final model with Bidirectional LSTMs ---\n","final_model = Sequential([\n","    Input(shape=(time_step, X_seq.shape[2])),\n","    Bidirectional(LSTM(150, return_sequences=True)),\n","    Dropout(0.2),\n","    Bidirectional(LSTM(150, return_sequences=True)),\n","    Dropout(0.2),\n","    Bidirectional(LSTM(64)),\n","    Dropout(0.2),\n","    Dense(64, activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","final_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# --- Train the final model on the entire dataset ---\n","final_model.fit(\n","    X_seq,\n","    y_seq,\n","    epochs=30, # A reasonable number of epochs based on previous runs\n","    batch_size=64,\n","    class_weight=final_class_weights_dict,\n","    verbose=1\n",")\n","\n","# --- Prepare the last 90 days of data for prediction ---\n","last_days = X_scaled[-time_step:]\n","prediction_input = last_days.reshape(1, time_step, X_df.shape[1])\n","\n","# --- Make the prediction ---\n","prediction_probs = final_model.predict(prediction_input)\n","predicted_class = np.argmax(prediction_probs, axis=1)[0]\n","\n","# --- Display the prediction ---\n","last_date_in_data = X_df.index[-1]\n","prediction_date = last_date_in_data + pd.Timedelta(days=1)\n","\n","print(\"\\n\\n=====================================================\")\n","print(f\"      PREDICTION FOR CHENNAI WATER CRISIS\")\n","print(\"=====================================================\")\n","print(f\"Based on data up to: {last_date_in_data.strftime('%Y-%m-%d')}\")\n","print(f\"Predicted Crisis Level for {prediction_date.strftime('%Y-%m-%d')}: {predicted_class}\")\n","print(\"=====================================================\")\n","print(\"\\nCrisis Levels:\")\n","print(\"0: No Crisis\")\n","print(\"1: Moderate Crisis\")\n","print(\"2: Severe Crisis\")\n","print(\"3: Extreme Crisis\")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"gTT-CPl-odka","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gTT-CPl-odka","outputId":"bd1bcb82-2aae-406f-91d8-560fa538e27a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data loaded and merged successfully.\n","DataFrame shape: (3842, 144)\n","\n","--- Performing Advanced Feature Engineering ---\n","Shape after feature engineering: (3813, 267)\n","\n","--- Performing Feature Selection with XGBoost ---\n","Selected Top 75 features.\n","\n","--- Class Distribution Analysis ---\n","Number of unique crisis levels (classes): 4\n","Unique target values: [0 1 2 3]\n","\n","Overall class distribution in the entire dataset:\n","Crisis_Target_V2\n","0    1295\n","1    1644\n","2     747\n","3     127\n","Name: count, dtype: int64\n","\n","--- Starting 5-Fold Time-Series Cross-Validation with Optimized Bi-GRU Model ---\n","\n","===== FOLD 1/5 =====\n","Class Weights for this fold: {0: np.float64(1.2818930041152263), 1: np.float64(0.5165837479270315), 2: np.float64(3.519774011299435)}\n","Epoch 1/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.4456 - loss: 0.9963 - val_accuracy: 0.7403 - val_loss: 0.9237\n","Epoch 2/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 848ms/step - accuracy: 0.8310 - loss: 0.3521 - val_accuracy: 0.6758 - val_loss: 1.2783\n","Epoch 3/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 848ms/step - accuracy: 0.9288 - loss: 0.1824 - val_accuracy: 0.6613 - val_loss: 1.5642\n","Epoch 4/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 985ms/step - accuracy: 0.9735 - loss: 0.0838 - val_accuracy: 0.6919 - val_loss: 1.3619\n","Epoch 5/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 854ms/step - accuracy: 0.9737 - loss: 0.0640 - val_accuracy: 0.6935 - val_loss: 1.1738\n","Epoch 6/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 976ms/step - accuracy: 0.9550 - loss: 0.1103 - val_accuracy: 0.6419 - val_loss: 1.2839\n","Epoch 7/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 967ms/step - accuracy: 0.9717 - loss: 0.0751 - val_accuracy: 0.6306 - val_loss: 1.4172\n","Epoch 8/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 849ms/step - accuracy: 0.9718 - loss: 0.0815 - val_accuracy: 0.6048 - val_loss: 1.5060\n","Epoch 9/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 974ms/step - accuracy: 0.9685 - loss: 0.0597 - val_accuracy: 0.5677 - val_loss: 1.6859\n","Epoch 10/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 825ms/step - accuracy: 0.9728 - loss: 0.0620 - val_accuracy: 0.6048 - val_loss: 1.5157\n","Epoch 11/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 969ms/step - accuracy: 0.9585 - loss: 0.0710 - val_accuracy: 0.5919 - val_loss: 1.6271\n","Epoch 12/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 970ms/step - accuracy: 0.9836 - loss: 0.0495 - val_accuracy: 0.5903 - val_loss: 1.7891\n","Epoch 13/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 973ms/step - accuracy: 0.9823 - loss: 0.0683 - val_accuracy: 0.6210 - val_loss: 1.4069\n","Epoch 14/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 970ms/step - accuracy: 0.9852 - loss: 0.0434 - val_accuracy: 0.6371 - val_loss: 1.2196\n","Epoch 15/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 977ms/step - accuracy: 0.9863 - loss: 0.0394 - val_accuracy: 0.6129 - val_loss: 1.6177\n","Epoch 16/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 925ms/step - accuracy: 0.9680 - loss: 0.0605 - val_accuracy: 0.6274 - val_loss: 1.4492\n","Epoch 17/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 968ms/step - accuracy: 0.9786 - loss: 0.0456 - val_accuracy: 0.5935 - val_loss: 1.5589\n","Epoch 18/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 974ms/step - accuracy: 0.9811 - loss: 0.0653 - val_accuracy: 0.6677 - val_loss: 1.2784\n","Epoch 19/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 845ms/step - accuracy: 0.9723 - loss: 0.0548 - val_accuracy: 0.6581 - val_loss: 1.0905\n","Epoch 20/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 841ms/step - accuracy: 0.9670 - loss: 0.0636 - val_accuracy: 0.5452 - val_loss: 2.1048\n","Epoch 21/150\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 929ms/step - accuracy: 0.9714 - loss: 0.0558 - val_accuracy: 0.5710 - val_loss: 2.0106\n","Epoch 21: early stopping\n","Restoring model weights from the end of the best epoch: 1.\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step\n","\n","Optimized Bi-GRU Accuracy for Fold 1: 0.7403\n","\n","===== FOLD 2/5 =====\n","Class Weights for this fold: {0: np.float64(1.253024193548387), 1: np.float64(0.46173848439821696), 2: np.float64(1.1178057553956835), 3: np.float64(7.0625)}\n","Epoch 1/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 875ms/step - accuracy: 0.3359 - loss: 1.2481 - val_accuracy: 0.6839 - val_loss: 0.6749\n","Epoch 2/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 784ms/step - accuracy: 0.8246 - loss: 0.4436 - val_accuracy: 0.8113 - val_loss: 0.3221\n","Epoch 3/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 843ms/step - accuracy: 0.9078 - loss: 0.2102 - val_accuracy: 0.9339 - val_loss: 0.2189\n","Epoch 4/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 851ms/step - accuracy: 0.9675 - loss: 0.0927 - val_accuracy: 0.9403 - val_loss: 0.1591\n","Epoch 5/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 849ms/step - accuracy: 0.9594 - loss: 0.1250 - val_accuracy: 0.9419 - val_loss: 0.1754\n","Epoch 6/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 846ms/step - accuracy: 0.9546 - loss: 0.0959 - val_accuracy: 0.8919 - val_loss: 0.3364\n","Epoch 7/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 779ms/step - accuracy: 0.9759 - loss: 0.0831 - val_accuracy: 0.8919 - val_loss: 0.3094\n","Epoch 8/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 846ms/step - accuracy: 0.9819 - loss: 0.0502 - val_accuracy: 0.9210 - val_loss: 0.2108\n","Epoch 9/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 790ms/step - accuracy: 0.9722 - loss: 0.0710 - val_accuracy: 0.8661 - val_loss: 0.5031\n","Epoch 10/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 848ms/step - accuracy: 0.9681 - loss: 0.1607 - val_accuracy: 0.9194 - val_loss: 0.1894\n","Epoch 11/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 850ms/step - accuracy: 0.9622 - loss: 0.1108 - val_accuracy: 0.8919 - val_loss: 0.2269\n","Epoch 12/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 891ms/step - accuracy: 0.9746 - loss: 0.0659 - val_accuracy: 0.9290 - val_loss: 0.2549\n","Epoch 13/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 854ms/step - accuracy: 0.9757 - loss: 0.0677 - val_accuracy: 0.9403 - val_loss: 0.1978\n","Epoch 14/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 801ms/step - accuracy: 0.9828 - loss: 0.0515 - val_accuracy: 0.9065 - val_loss: 0.2982\n","Epoch 15/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 771ms/step - accuracy: 0.9738 - loss: 0.0800 - val_accuracy: 0.8581 - val_loss: 0.3617\n","Epoch 16/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 784ms/step - accuracy: 0.9745 - loss: 0.1118 - val_accuracy: 0.9452 - val_loss: 0.1544\n","Epoch 17/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 844ms/step - accuracy: 0.9797 - loss: 0.0678 - val_accuracy: 0.9371 - val_loss: 0.2003\n","Epoch 18/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 852ms/step - accuracy: 0.9813 - loss: 0.0489 - val_accuracy: 0.9210 - val_loss: 0.1965\n","Epoch 19/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 849ms/step - accuracy: 0.9859 - loss: 0.0352 - val_accuracy: 0.9274 - val_loss: 0.2738\n","Epoch 20/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 798ms/step - accuracy: 0.9768 - loss: 0.0495 - val_accuracy: 0.9387 - val_loss: 0.2278\n","Epoch 21/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 781ms/step - accuracy: 0.9799 - loss: 0.0377 - val_accuracy: 0.8677 - val_loss: 0.3998\n","Epoch 22/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 790ms/step - accuracy: 0.9772 - loss: 0.0557 - val_accuracy: 0.9403 - val_loss: 0.2093\n","Epoch 23/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 786ms/step - accuracy: 0.9692 - loss: 0.0609 - val_accuracy: 0.9355 - val_loss: 0.2356\n","Epoch 24/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 841ms/step - accuracy: 0.9794 - loss: 0.0710 - val_accuracy: 0.9339 - val_loss: 0.2994\n","Epoch 25/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 842ms/step - accuracy: 0.9828 - loss: 0.0386 - val_accuracy: 0.8629 - val_loss: 0.5665\n","Epoch 26/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 843ms/step - accuracy: 0.9798 - loss: 0.0463 - val_accuracy: 0.8935 - val_loss: 0.2763\n","Epoch 27/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 766ms/step - accuracy: 0.9796 - loss: 0.0903 - val_accuracy: 0.9419 - val_loss: 0.1792\n","Epoch 28/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 837ms/step - accuracy: 0.9788 - loss: 0.0565 - val_accuracy: 0.8968 - val_loss: 0.3775\n","Epoch 29/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 841ms/step - accuracy: 0.9730 - loss: 0.0429 - val_accuracy: 0.9452 - val_loss: 0.1740\n","Epoch 30/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 853ms/step - accuracy: 0.9749 - loss: 0.0571 - val_accuracy: 0.8903 - val_loss: 0.2177\n","Epoch 31/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 842ms/step - accuracy: 0.9827 - loss: 0.0466 - val_accuracy: 0.9226 - val_loss: 0.2401\n","Epoch 32/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 836ms/step - accuracy: 0.9806 - loss: 0.0454 - val_accuracy: 0.8871 - val_loss: 0.3424\n","Epoch 33/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 845ms/step - accuracy: 0.9783 - loss: 0.0373 - val_accuracy: 0.9258 - val_loss: 0.2797\n","Epoch 34/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 781ms/step - accuracy: 0.9831 - loss: 0.0353 - val_accuracy: 0.9355 - val_loss: 0.2714\n","Epoch 35/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 774ms/step - accuracy: 0.9773 - loss: 0.0633 - val_accuracy: 0.9484 - val_loss: 0.1816\n","Epoch 36/150\n","\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 765ms/step - accuracy: 0.9508 - loss: 0.1074 - val_accuracy: 0.9339 - val_loss: 0.2656\n","Epoch 36: early stopping\n","Restoring model weights from the end of the best epoch: 16.\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step\n","\n","Optimized Bi-GRU Accuracy for Fold 2: 0.9452\n","\n","===== FOLD 3/5 =====\n","Class Weights for this fold: {0: np.float64(1.2160574412532636), 1: np.float64(0.5040584415584416), 2: np.float64(1.0856643356643356), 3: np.float64(3.6673228346456694)}\n","Epoch 1/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 801ms/step - accuracy: 0.6022 - loss: 0.9249 - val_accuracy: 0.5597 - val_loss: 1.1454\n","Epoch 2/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 785ms/step - accuracy: 0.9365 - loss: 0.1991 - val_accuracy: 0.5887 - val_loss: 1.0394\n","Epoch 3/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 802ms/step - accuracy: 0.9680 - loss: 0.1030 - val_accuracy: 0.7742 - val_loss: 0.6941\n","Epoch 4/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 776ms/step - accuracy: 0.9627 - loss: 0.1149 - val_accuracy: 0.5984 - val_loss: 1.2407\n","Epoch 5/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 782ms/step - accuracy: 0.9743 - loss: 0.0756 - val_accuracy: 0.6726 - val_loss: 1.0067\n","Epoch 6/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 781ms/step - accuracy: 0.9589 - loss: 0.1147 - val_accuracy: 0.6613 - val_loss: 1.0397\n","Epoch 7/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 747ms/step - accuracy: 0.9760 - loss: 0.0654 - val_accuracy: 0.7194 - val_loss: 0.8788\n","Epoch 8/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 747ms/step - accuracy: 0.9796 - loss: 0.0674 - val_accuracy: 0.5968 - val_loss: 1.6541\n","Epoch 9/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 802ms/step - accuracy: 0.9750 - loss: 0.0719 - val_accuracy: 0.5548 - val_loss: 1.8326\n","Epoch 10/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 794ms/step - accuracy: 0.9735 - loss: 0.0728 - val_accuracy: 0.5952 - val_loss: 1.5303\n","Epoch 11/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 791ms/step - accuracy: 0.9824 - loss: 0.0391 - val_accuracy: 0.6597 - val_loss: 1.3580\n","Epoch 12/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 786ms/step - accuracy: 0.9755 - loss: 0.0619 - val_accuracy: 0.7129 - val_loss: 0.8325\n","Epoch 13/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 775ms/step - accuracy: 0.9718 - loss: 0.0791 - val_accuracy: 0.6097 - val_loss: 1.5506\n","Epoch 14/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 803ms/step - accuracy: 0.9670 - loss: 0.0821 - val_accuracy: 0.6339 - val_loss: 1.3789\n","Epoch 15/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 798ms/step - accuracy: 0.9756 - loss: 0.0536 - val_accuracy: 0.6290 - val_loss: 1.6685\n","Epoch 16/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 788ms/step - accuracy: 0.9755 - loss: 0.0817 - val_accuracy: 0.5903 - val_loss: 1.8860\n","Epoch 17/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 793ms/step - accuracy: 0.9778 - loss: 0.0490 - val_accuracy: 0.5935 - val_loss: 1.7242\n","Epoch 18/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 814ms/step - accuracy: 0.9781 - loss: 0.0518 - val_accuracy: 0.6726 - val_loss: 1.5933\n","Epoch 19/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 794ms/step - accuracy: 0.9836 - loss: 0.0421 - val_accuracy: 0.6323 - val_loss: 1.4940\n","Epoch 20/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 763ms/step - accuracy: 0.9774 - loss: 0.0525 - val_accuracy: 0.5548 - val_loss: 2.0878\n","Epoch 21/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 767ms/step - accuracy: 0.9833 - loss: 0.0476 - val_accuracy: 0.5984 - val_loss: 1.7353\n","Epoch 22/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 801ms/step - accuracy: 0.9874 - loss: 0.0406 - val_accuracy: 0.6226 - val_loss: 1.6191\n","Epoch 23/150\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 789ms/step - accuracy: 0.9852 - loss: 0.0452 - val_accuracy: 0.6742 - val_loss: 1.6437\n","Epoch 23: early stopping\n","Restoring model weights from the end of the best epoch: 3.\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step\n","\n","Optimized Bi-GRU Accuracy for Fold 3: 0.7742\n","\n","===== FOLD 4/5 =====\n","Class Weights for this fold: {0: np.float64(0.8597645429362881), 1: np.float64(0.5512877442273535), 2: np.float64(1.2219488188976377), 3: np.float64(4.887795275590551)}\n","Epoch 1/150\n","\u001b[1m28/78\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 779ms/step - accuracy: 0.3682 - loss: 1.1694"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import TimeSeriesSplit\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, Bidirectional, GRU\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","import xgboost as xgb\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# --- 1. Load and Prepare Data ---\n","\n","try:\n","    # Load the features and target datasets\n","    features_df = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/E:/projects/water_crises_management/chennaiWaterCrisis/Datasets/chennai_features_for_lstm.csv')\n","    target_df = pd.read_csv('/content/drive/Othercomputers/My Laptop (1)/E:/projects/water_crises_management/chennaiWaterCrisis/Datasets/chennai_target_for_lstm.csv')\n","\n","    # Convert 'Date' column to datetime objects\n","    features_df['Date'] = pd.to_datetime(features_df['Date'])\n","    target_df['Date'] = pd.to_datetime(target_df['Date'])\n","\n","    # Merge the two dataframes on the 'Date' column\n","    df = pd.merge(features_df, target_df, on='Date')\n","\n","    # Set 'Date' as the index\n","    df.set_index('Date', inplace=True)\n","\n","    print(\"Data loaded and merged successfully.\")\n","    print(\"DataFrame shape:\", df.shape)\n","\n","except FileNotFoundError as e:\n","    print(f\"Error: {e}. Please make sure 'chennai_features_for_lstm.csv' and 'chennai_target_for_lstm.csv' are in the same directory as the script.\")\n","    exit()\n","\n","\n","# --- 2. Advanced Feature Engineering ---\n","print(\"\\n--- Performing Advanced Feature Engineering ---\")\n","\n","# Make a copy to avoid SettingWithCopyWarning\n","X_df_full = df.drop('Crisis_Target_V2', axis=1).copy()\n","y_df = df['Crisis_Target_V2']\n","\n","# Create a list to hold new feature DataFrames to avoid fragmentation\n","new_features_list = []\n","\n","# a. Reservoir Capacity Percentage\n","reservoirs = ['CHEMBARAMBAKKAM', 'CHOLAVARAM', 'POONDI', 'PUZHAL', 'VEERANAM', 'KANNANKOTTAI_THERVOY_KANDIGAI']\n","temp_df = pd.DataFrame(index=X_df_full.index)\n","for res in reservoirs:\n","    storage_col = f'Storage_mcft_{res}'\n","    capacity_col = f'Full_Capacity_mcft_{res}'\n","    if storage_col in X_df_full.columns and capacity_col in X_df_full.columns:\n","        temp_df[f'Capacity_perc_{res}'] = (X_df_full[storage_col] / (X_df_full[capacity_col] + 1e-6)) * 100\n","new_features_list.append(temp_df)\n","\n","\n","# b. Lag Features for all reservoirs and key weather metrics\n","lag_features = []\n","for res in reservoirs:\n","    lag_features.append(f'Rainfall_mm_{res}')\n","    lag_features.append(f'Inflow_cusecs_{res}')\n","lag_features.extend(['temperature_mean_celsius', 'relative_humidity_mean_percent'])\n","lags = [1, 3, 7]\n","temp_df = pd.DataFrame(index=X_df_full.index)\n","for feature in lag_features:\n","    if feature in X_df_full.columns:\n","        for lag in lags:\n","            temp_df[f'{feature}_lag_{lag}'] = X_df_full[feature].shift(lag)\n","new_features_list.append(temp_df)\n","\n","\n","# c. Rolling Averages & Sums for all major reservoirs\n","rolling_features = []\n","for res in reservoirs:\n","    rolling_features.append(f'Rainfall_mm_{res}')\n","    rolling_features.append(f'Inflow_cusecs_{res}')\n","windows = [7, 14, 30]\n","temp_df = pd.DataFrame(index=X_df_full.index)\n","for feature in rolling_features:\n","    if feature in X_df_full.columns:\n","        for window in windows:\n","            temp_df[f'{feature}_roll_mean_{window}'] = X_df_full[feature].rolling(window=window).mean()\n","            temp_df[f'{feature}_roll_sum_{window}'] = X_df_full[feature].rolling(window=window).sum()\n","new_features_list.append(temp_df)\n","\n","\n","# d. Time-Based Features\n","temp_df = pd.DataFrame(index=X_df_full.index)\n","temp_df['month'] = X_df_full.index.month\n","temp_df['week_of_year'] = X_df_full.index.isocalendar().week.astype(int)\n","temp_df['day_of_year'] = X_df_full.index.dayofyear\n","new_features_list.append(temp_df)\n","\n","# e. Interaction Features\n","if 'temperature_mean_celsius' in X_df_full.columns and 'relative_humidity_mean_percent' in X_df_full.columns:\n","    temp_df = pd.DataFrame(index=X_df_full.index)\n","    temp_df['temp_humidity_interaction'] = X_df_full['temperature_mean_celsius'] / (X_df_full['relative_humidity_mean_percent'] + 1e-6)\n","    new_features_list.append(temp_df)\n","\n","# Concatenate all new features at once for efficiency\n","X_df_full = pd.concat([X_df_full] + new_features_list, axis=1)\n","\n","\n","# Drop rows with NaN values created by feature engineering\n","X_df_full.dropna(inplace=True)\n","y_df = y_df.loc[X_df_full.index]\n","\n","print(f\"Shape after feature engineering: {X_df_full.shape}\")\n","\n","\n","# --- 3. Intelligent Feature Selection using XGBoost ---\n","print(\"\\n--- Performing Feature Selection with XGBoost ---\")\n","\n","# Train a simple XGBoost model to get feature importances\n","xgb_selector = xgb.XGBClassifier(objective='multi:softmax', eval_metric='mlogloss')\n","xgb_selector.fit(X_df_full.values, y_df.values) # Pass NumPy arrays here\n","\n","# Get feature importances\n","importances = xgb_selector.feature_importances_\n","feature_names = X_df_full.columns\n","\n","# Create a DataFrame for visualization\n","feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n","feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n","\n","# Select the top N features\n","N_FEATURES = 75\n","top_features = feature_importance_df.head(N_FEATURES)['feature'].tolist()\n","print(f\"Selected Top {N_FEATURES} features.\")\n","\n","# Create the final DataFrame with only the selected features\n","X_df = X_df_full[top_features]\n","\n","\n","# --- 4. Preprocess the Data ---\n","\n","# --- Diagnostic: Check Class Distribution ---\n","print(\"\\n--- Class Distribution Analysis ---\")\n","num_classes = len(y_df.unique())\n","print(f\"Number of unique crisis levels (classes): {num_classes}\")\n","print(f\"Unique target values: {np.sort(y_df.unique())}\")\n","print(\"\\nOverall class distribution in the entire dataset:\")\n","print(y_df.value_counts().sort_index())\n","\n","# Scale the selected features to be between 0 and 1.\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","X_scaled = scaler.fit_transform(X_df)\n","\n","# --- 5. Create Time-Series Sequences ---\n","def create_dataset(X, y, time_step=1):\n","    dataX, dataY = [], []\n","    for i in range(len(X) - time_step):\n","        a = X[i:(i + time_step), :]\n","        dataX.append(a)\n","        dataY.append(y[i + time_step])\n","    return np.array(dataX), np.array(dataY)\n","\n","time_step = 90\n","X_seq, y_seq = create_dataset(X_scaled, y_df.values, time_step)\n","\n","\n","# --- 6. Build and Train Optimized Bidirectional GRU with Cross-Validation ---\n","\n","n_splits = 5\n","tscv = TimeSeriesSplit(n_splits=n_splits)\n","\n","fold_accuracies = []\n","all_y_test = []\n","all_y_pred = []\n","\n","print(f\"\\n--- Starting {n_splits}-Fold Time-Series Cross-Validation with Optimized Bi-GRU Model ---\")\n","\n","for fold, (train_index, test_index) in enumerate(tscv.split(X_seq)):\n","    print(f\"\\n===== FOLD {fold + 1}/{n_splits} =====\")\n","    X_train, X_test = X_seq[train_index], X_seq[test_index]\n","    y_train, y_test = y_seq[train_index], y_seq[test_index]\n","\n","    # --- Handle Class Imbalance with Class Weights ---\n","    class_weights = compute_class_weight(\n","        class_weight='balanced',\n","        classes=np.unique(y_train),\n","        y=y_train\n","    )\n","    class_weights_dict = dict(enumerate(class_weights))\n","    print(\"Class Weights for this fold:\", class_weights_dict)\n","\n","    # --- Build the Optimized Bidirectional GRU Model ---\n","    model = Sequential([\n","        Input(shape=(time_step, X_train.shape[-1])),\n","        Bidirectional(GRU(128, return_sequences=True)),\n","        Dropout(0.25),\n","        Bidirectional(GRU(128, return_sequences=True)),\n","        Dropout(0.25),\n","        Bidirectional(GRU(64)),\n","        Dropout(0.25),\n","        Dense(64, activation='relu'),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","\n","    optimizer = Adam(learning_rate=0.0005)\n","    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True)\n","\n","    model.fit(\n","        X_train, y_train,\n","        validation_data=(X_test, y_test),\n","        epochs=150,\n","        batch_size=32,\n","        class_weight=class_weights_dict,\n","        callbacks=[early_stopping],\n","        verbose=1\n","    )\n","    pred_probs = model.predict(X_test)\n","    y_pred = np.argmax(pred_probs, axis=1)\n","\n","    fold_accuracy = accuracy_score(y_test, y_pred)\n","    fold_accuracies.append(fold_accuracy)\n","    print(f\"\\nOptimized Bi-GRU Accuracy for Fold {fold + 1}: {fold_accuracy:.4f}\")\n","\n","    all_y_test.extend(y_test)\n","    all_y_pred.extend(y_pred)\n","\n","\n","# --- 7. Final Model Evaluation ---\n","print(\"\\n\\n--- Overall Optimized Bi-GRU Model Performance (Across All Folds) ---\")\n","print(f\"Average Cross-Validation Accuracy: {np.mean(fold_accuracies):.4f} (+/- {np.std(fold_accuracies):.4f})\")\n","\n","# --- Overall Classification Report ---\n","print(\"\\nOverall Classification Report:\")\n","report = classification_report(all_y_test, all_y_pred, labels=np.sort(y_df.unique()), zero_division=0)\n","print(report)\n","\n","# --- Overall Confusion Matrix ---\n","print(\"\\n--- Plotting Overall Confusion Matrix ---\")\n","cm = confusion_matrix(all_y_test, all_y_pred, labels=np.sort(y_df.unique()))\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=np.sort(y_df.unique()),\n","            yticklabels=np.sort(y_df.unique()))\n","plt.title('Overall Optimized Bi-GRU Confusion Matrix (All Folds)', fontsize=16, fontweight='bold')\n","plt.ylabel('Actual Label', fontsize=12)\n","plt.xlabel('Predicted Label', fontsize=12)\n","plt.show()\n","print(\"Confusion Matrix plot displayed.\")\n","\n","\n","# --- 8. Train Final Model and Make Prediction for Tomorrow ---\n","\n","print(\"\\n\\n--- Training Final Optimized Model on All Data for Prediction ---\")\n","\n","# --- Final Class Weights ---\n","final_class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_seq), y=y_seq)\n","final_class_weights_dict = dict(enumerate(final_class_weights))\n","\n","# --- Build the final model ---\n","final_model = Sequential([\n","    Input(shape=(time_step, X_seq.shape[-1])),\n","    Bidirectional(GRU(128, return_sequences=True)),\n","    Dropout(0.25),\n","    Bidirectional(GRU(128, return_sequences=True)),\n","    Dropout(0.25),\n","    Bidirectional(GRU(64)),\n","    Dropout(0.25),\n","    Dense(64, activation='relu'),\n","    Dense(num_classes, activation='softmax')\n","])\n","final_optimizer = Adam(learning_rate=0.0005)\n","final_model.compile(optimizer=final_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# --- Train the final model ---\n","final_model.fit(X_seq, y_seq, epochs=40, batch_size=32, class_weight=final_class_weights_dict, verbose=1)\n","\n","# --- Prepare input for prediction ---\n","last_days_scaled = X_scaled[-time_step:]\n","prediction_input = last_days_scaled.reshape(1, time_step, X_df.shape[1])\n","\n","# --- Make final prediction ---\n","final_pred_probs = final_model.predict(prediction_input)\n","predicted_class = np.argmax(final_pred_probs, axis=1)[0]\n","\n","# --- Display the prediction ---\n","last_date_in_data = X_df.index[-1]\n","prediction_date = last_date_in_data + pd.Timedelta(days=1)\n","\n","print(\"\\n\\n=====================================================\")\n","print(f\"      OPTIMIZED GRU PREDICTION FOR CHENNAI WATER CRISIS\")\n","print(\"=====================================================\")\n","print(f\"Based on data up to: {last_date_in_data.strftime('%Y-%m-%d')}\")\n","print(f\"Predicted Crisis Level for {prediction_date.strftime('%Y-%m-%d')}: {predicted_class}\")\n","print(\"=====================================================\")\n","print(\"\\nCrisis Levels:\")\n","print(\"0: No Crisis\")\n","print(\"1: Moderate Crisis\")\n","print(\"2: Severe Crisis\")\n","print(\"3: Extreme Crisis\")"]},{"cell_type":"code","execution_count":null,"id":"x-EAqqzsqPii","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30757,"status":"ok","timestamp":1756055362838,"user":{"displayName":"Pranav Bhat","userId":"05304972169025204322"},"user_tz":-330},"id":"x-EAqqzsqPii","outputId":"15cd6134-1a07-4cdf-df1c-4f95790de6a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}